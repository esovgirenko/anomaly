# Руководство по мониторингу LLM-агентов

## Что такое LLM-агенты?

**LLM-агенты** (Large Language Model Agents) — это автономные системы на базе больших языковых моделей, способные:

- **Воспринимать окружение** — анализировать входные данные и контекст
- **Планировать действия** — определять последовательность шагов для достижения цели
- **Достигать целей** — выполнять задачи без жесткого программирования
- **Адаптироваться** — изменять поведение на основе контекста

### Примеры LLM-агентов:

- Чат-боты для поддержки клиентов (GPT-4, Claude)
- Системы обработки и анализа документов
- Автоматические ассистенты для ответов на вопросы
- Агенты для генерации контента
- Системы автоматизации задач с использованием LLM

## Зачем нужен мониторинг LLM-агентов?

Работа с LLM-агентами имеет свои особенности и риски:

1. **Стоимость** — каждый запрос к API стоит деньги, нужно контролировать расходы
2. **Качество** — LLM могут галлюцинировать или давать неправильные ответы
3. **Производительность** — ответы могут быть медленными, особенно для сложных задач
4. **Лимиты** — API провайдеры ограничивают количество запросов
5. **Токены** — нужно следить за использованием токенов (влияет на стоимость)
6. **Контекст** — превышение размера контекстного окна может привести к ошибкам

## Метрики, которые отслеживает система

### 1. Токены (Token Usage)

- **input_tokens** — токены во входном запросе
- **output_tokens** — токены в ответе модели
- **total_tokens** — общее количество токенов
- **Аномалии**: скачки использования, превышение лимитов, неэффективные соотношения

### 2. Задержка (Latency)

- **latency_ms** — время ответа в миллисекундах
- **response_time_p50/p95/p99** — процентили времени ответа
- **Аномалии**: слишком долгие ответы, скачки задержки

### 3. Стоимость (Cost)

- **cost_usd** — стоимость одного запроса в долларах
- **daily_cost** — дневные расходы
- **Аномалии**: превышение бюджета, неожиданно дорогие запросы

### 4. Качество (Quality)

- **quality_score** — общая оценка качества (0.0-1.0)
- **coherence_score** — связность ответа (0.0-1.0)
- **relevance_score** — релевантность ответа (0.0-1.0)
- **hallucination_detected** — обнаружены ли галлюцинации
- **factual_errors** — количество фактологических ошибок
- **Аномалии**: снижение качества, галлюцинации, ошибки

### 5. Rate Limits

- **rate_limit_remaining** — оставшиеся запросы
- **requests_per_minute** — текущая скорость запросов
- **Аномалии**: приближение к лимиту, превышение лимита

### 6. Контекстное окно (Context Window)

- **context_window_usage** — процент использования (0.0-1.0)
- **Аномалии**: приближение к переполнению, переполнение

## Типы обнаруженных аномалий

### TOKEN_USAGE
Аномальное использование токенов:
- Резкий скачок количества токенов
- Превышение максимального лимита
- Неэффективное соотношение input/output токенов

### LATENCY
Проблемы с производительностью:
- Слишком долгие ответы
- Резкие скачки задержки
- Деградация производительности

### COST
Проблемы со стоимостью:
- Превышение дневного бюджета
- Неожиданно дорогие запросы
- Резкие скачки стоимости

### QUALITY
Проблемы с качеством:
- Обнаружены галлюцинации
- Фактологические ошибки
- Низкие оценки качества, связности, релевантности

### RATE_LIMIT
Проблемы с лимитами API:
- Приближение к лимиту запросов
- Превышение rate limit

### CONTEXT_OVERFLOW
Проблемы с контекстным окном:
- Высокое использование контекста
- Риск переполнения

## Примеры конфигурации

### Базовая конфигурация для LLM-агента

```yaml
# config/agents.yaml
agents:
  - agent_id: gpt4_chatbot
    metrics_endpoint: http://localhost:9090/metrics
    metadata:
      name: "GPT-4 Chatbot"
      model: "gpt-4"
      provider: "openai"
      context_window_size: 8192
      rate_limit: 500
```

### Настройка детекторов

```yaml
# config/config.yaml
detectors:
  llm:
    token_usage:
      enabled: true
      max_tokens_threshold: 50000
      token_spike_threshold: 3.0
    
    cost:
      enabled: true
      daily_budget_usd: 100.0
      cost_threshold_usd: 1.0
    
    quality:
      enabled: true
      quality_threshold: 0.7
```

### Правила обнаружения

```yaml
# config/rules.yaml
rules:
  - name: high_token_usage
    description: Использование токенов превышает 50K
    anomaly_type: token_usage
    severity: 0.8
    conditions:
      - metric: total_tokens
        operator: ">"
        value: 50000
  
  - name: quality_degradation
    description: Качество ответов упало
    anomaly_type: quality
    severity: 0.7
    conditions:
      - metric: quality_score
        operator: "<"
        value: 0.6
```

## Примеры кода

### Регистрация LLM-агента

```python
from anomaly_detection import AnomalyDetectionSystem

system = AnomalyDetectionSystem(config='config/config.yaml')

# Регистрация агента
agent = system.register_agent(
    agent_id='gpt4_chatbot',
    metadata={
        'model': 'gpt-4',
        'provider': 'openai',
        'context_window_size': 8192,
        'rate_limit': 500
    }
)
```

### Отправка метрик

```python
# После выполнения запроса к LLM
metrics = {
    "input_tokens": 1500,
    "output_tokens": 800,
    "total_tokens": 2300,
    "latency_ms": 2500.0,
    "cost_usd": 0.04,
    "quality_score": 0.92,
    "coherence_score": 0.90,
    "relevance_score": 0.91,
    "context_window_usage": 0.28,
    "hallucination_detected": False,
    "factual_errors": 0,
    "model": "gpt-4",
    "provider": "openai",
}

# Детекция аномалий
monitor = system._monitors.get('gpt4_chatbot')
anomalies = await monitor.detect_anomalies(metrics)

# Регистрация найденных аномалий
for anomaly in anomalies:
    if system.registry.register(anomaly):
        print(f"Обнаружена аномалия: {anomaly.description}")
```

## Рекомендации

### 1. Настройте бюджет

Установите дневной бюджет в `CostDetector`:
```yaml
cost:
  daily_budget_usd: 100.0
```

### 2. Мониторьте качество

Включите детектор качества и установите пороги:
```yaml
quality:
  quality_threshold: 0.7
  coherence_threshold: 0.7
```

### 3. Контролируйте токены

Установите максимальный лимит токенов:
```yaml
token_usage:
  max_tokens_threshold: 50000
```

### 4. Настройте алерты

Используйте систему алертов для критических аномалий:
- Превышение бюджета
- Обнаружение галлюцинаций
- Превышение rate limits

### 5. Анализируйте тренды

Используйте статистические детекторы для обнаружения трендов:
- Деградация качества со временем
- Рост стоимости
- Увеличение задержки

## Частые проблемы и решения

### Проблема: Слишком высокая стоимость

**Решение:**
1. Проверьте использование токенов
2. Установите дневной бюджет
3. Оптимизируйте промпты (меньше токенов = меньше стоимость)

### Проблема: Низкое качество ответов

**Решение:**
1. Включите детектор качества
2. Настройте пороги качества
3. Используйте более мощные модели (если возможно)
4. Улучшите промпты

### Проблема: Превышение rate limits

**Решение:**
1. Включите RateLimitDetector
2. Реализуйте очередь запросов
3. Используйте кэширование ответов
4. Рассмотрите переход на более высокий тариф

### Проблема: Переполнение контекста

**Решение:**
1. Включите ContextOverflowDetector
2. Разбивайте большие документы на части
3. Используйте суммаризацию
4. Рассмотрите модели с большим контекстным окном

## Дополнительные ресурсы

- [Архитектура системы](ARCHITECTURE.md) - Подробное описание архитектуры
- [Основная документация](README.md)
- [Примеры использования](examples/llm_agent_example.py)
- [Симулятор для тестирования](examples/llm_agent_simulator.py)
- [Конфигурация детекторов](config/config.yaml)

